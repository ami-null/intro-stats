\documentclass[12pt, aspectratio=169]{beamer}

\input{../header}
\usepackage{booktabs}


\title{Central Tendency and Dispersion}
\author{Md. Aminul Islam Shazid}
\date{}


\begin{document}
    {
		\setbeamertemplate{footline}{}    % NO FOOTLINE FOR THESE TWO FRAMES
		\addtocounter{framenumber}{-2}    % not counting the title page and the outline in frame numbers

		\begin{frame}
			\titlepage
		\end{frame}

		\begin{frame}{Outline}
            \vfill
			\tableofcontents[subsectionstyle=hide]
            \vfill
		\end{frame}
	}

	\section{Central Tendency}

    \begin{frame}{Central Tendency}
        \begin{itemize}
            \item Observations of a variable tend to gather around a single value, this is known as central tendency
            \item Central tendency is a descriptive measure that represents the center or typical value of a variable
            \item It provides a summary of the values of the variable
        \end{itemize}
    \end{frame}


    \begin{frame}{Central Tendency (cont.)}
        \begin{itemize}
            \item Mean:
            \begin{itemize}
                \item Arithmetic mean
                \item Geometric mean
                \item Harmonic mean
            \end{itemize}
            \item Median
            \item Mode
        \end{itemize}
        These are different \textit{measures} of central tendency. They represent the ``average" value of a dataset in different ways.\\[0.25em]
        Depending on the \text{shape} of the distribution and the presence of outliers, different measures are used.
    \end{frame}


    \begin{frame}{Characteristics of a Good Measure}
        \begin{itemize}
            \item Clear and unambiguous definition so that the same data provides the same value of the measure
            \item Easy to understand and calculate
            \item Based on all or most of the observations in the sample
            \item Not unduly affected by outliers so that a few outliers does not distort the result too much
            \item Representative of the distribution so that the value lies within the range of the data and and describe its central location
            \item Capable of further mathematical treatment so that it can be used for further analysis
        \end{itemize}
    \end{frame}


    \begin{frame}{Arithmetic Mean}
        \begin{itemize}
            \item The arithmetic mean is the sum of all observations divided by the number of observations
            \item The population mean is denoted by $\mu$
            \item For a sample of values $x_1, x_2, \dots, x_n$ of a variable $X$, the sample mean is
            \[
                \bar{x} = \frac{1}{n}\sum_{i=1}^{n} x_i
            \]
            \item It uses all observations in the dataset
            \item The arithmetic mean is easy to compute and interpret
            \item It is \textit{sensitive} to extreme values (outliers)
            \item Therefore, it is most appropriate for numerical data that are symmetrically distributed
        \end{itemize}
    \end{frame}


    \begin{frame}{Example: Arithmetic Mean Using Frequency Table}
        \begin{center}
            \begin{tabular}{lcc}
                \toprule
                \textbf{Value, $x_i$} & \textbf{Frequency}, $f_i$ & $f_i \cdot x_i$ \\
                \midrule
                55 & 7  & 385\\
                60 & 10 & 600\\
                62 & 6  & 372\\
                65 & 4  & 260\\
                67 & 3  & 201\\
                \bottomrule
                \textbf{Total:} & 30 & 1818
            \end{tabular}
        \end{center}
        The mean, $\bar{x} = \frac{\sum_{i=1}^{n} f_i x_i}{\sum_{i=1}^{n} f_i} = \frac{1818}{30}=60.6$.\\[0.5em]

        If the data is grouped, then the class midpoints are treated as $x_i$.
    \end{frame}


    \begin{frame}{Arithmetic Mean for Grouped Data}
        \begin{center}
            \begin{tabular}{lccc}
                \toprule
                \textbf{Class interval} & \textbf{Class midpoint}, $x_i$ & \textbf{Frequency}, $x_i$ & $f_i \cdot x_i$\\
                \midrule
                5-30    & 17.5  & 7  & 122.5 \\
                30-55   & 42.5  & 10 & 425 \\
                55-80   & 67.5  & 6  & 405 \\
                80-105  & 92.5  & 4  & 370 \\
                105-130 & 117.5 & 3  & 352.5 \\
                \bottomrule
                 & \textbf{Total}: & 30 & 1675
            \end{tabular}
        \end{center}
        Mean = $1675/30 = 55.83$
    \end{frame}


    \begin{frame}{Weighted Mean}
        \begin{itemize}
            \item When caluclating average, sometimes some values may be more important than other values
            \item In the previous example, the observations appeared different number of times
            \item Therefore, each value has different level of influence over the center of the distribution
            \item This is called the weight of each value
            \item Another example is the calculation of CGPA where the total credit of each semester is the weight of the corresponding GPA
        \end{itemize}
    \end{frame}


    \begin{frame}{Geometric Mean}
        \begin{itemize}
            \item The geometric mean is a measure of central tendency defined as the $n$-th root of the product of $n$ positive observations
            \item For positive data $x_1, x_2, \dots, x_n$, the geometric mean is
            \[
                G = \left( \prod_{i=1}^{n} x_i \right)^{1/n}
            \]
            \item It is only defined for positive values
            \item The geometric mean is appropriate for data involving ratios, rates, or growth factors
            \item It reduces the influence of very large values compared to the arithmetic mean
            \item The geometric mean is commonly used for percentage changes and financial returns
        \end{itemize}
    \end{frame}


    \begin{frame}{Geometric Mean for Grouped Data}
        \begin{itemize}
            \item For grouped data, the geometric mean is calculated using class frequencies
            \item Let $x_1, x_2, \dots, x_k$ be the class midpoints and $f_1, f_2, \dots, f_k$ the corresponding frequencies
            \item The geometric mean is given by
            \[
                G = \left( \prod_{i=1}^{k} x_i^{\,f_i} \right)^{1/n},
            \]
            where $n = \sum_{i=1}^{k} f_i$
            \item In practice, the computation is often simplified using logarithms:
            \[
                \log G = \frac{1}{n} \sum_{i=1}^{k} f_i \log x_i
            \]
        \end{itemize}
    \end{frame}


    \begin{frame}{Harmonic mean}
        \begin{itemize}
            \item The harmonic mean is a measure of central tendency defined as the reciprocal of the arithmetic mean of reciprocals
            \item For positive data $x_1, x_2, \dots, x_n$, the harmonic mean is
            \[
                H = \frac{n}{\sum_{i=1}^{n} \frac{1}{x_i}}
            \]
            \item It is only defined for positive values
            \item The harmonic mean gives more weight to smaller observations
            \item It is appropriate for averaging rates or ratios, such as speeds or densities
            \item The harmonic mean is strongly affected by very small values
        \end{itemize}
    \end{frame}


    \begin{frame}{Harmonic Mean for Grouped Data}
        \begin{itemize}
            \item For grouped data, the harmonic mean is calculated using class frequencies
            \item Let $x_1, x_2, \dots, x_k$ be the class midpoints and $f_1, f_2, \dots, f_k$ the corresponding frequencies.
            \item The harmonic mean is given by
            \[
                H = \frac{n}{\sum_{i=1}^{k} \dfrac{f_i}{x_i}},
            \]
            where $n = \sum_{i=1}^{k} f_i$
        \end{itemize}
    \end{frame}


    \begin{frame}{Mode}
        \begin{itemize}
            \item The mode is the value that occurs most frequently in a dataset
            \item A dataset may have:
            \begin{itemize}
                \item one mode (unimodal),
                \item two modes (bimodal), or
                \item more than two modes (multimodal)
            \end{itemize}
            \item The mode can be used for both numerical and categorical data
            \item A dataset may have no mode if all values occur with the same frequency
            \item The mode is not affected by extreme values
            \item For grouped data, the mode is estimated using the modal class
        \end{itemize}
    \end{frame}


    \begin{frame}{Mode for Grouped Data}
        \[
            \textsf{Mode} = L_0 + \frac{l_1}{l_1 + l_2} \times c,
        \]
        where:
        \begin{itemize}
            \item $L_0$ is the lower limit of the modal class (class with the highest frequency)
            \item $l_1$ is the difference in Frequency between the modal class and the pre-modal class
            \item $l_2$ is the difference in Frequency between the modal class and the post-modal class
            \item $c$ is the class interval
        \end{itemize}
    \end{frame}


    \begin{frame}{Example: Mode for Grouped Data}
        \begin{center}
            \begin{tabular}{lcc}
                \toprule
                \textbf{Class interval} & \textbf{Frequency}\\
                \midrule
                5-30    & 7 \\
                30-55   & 10 \\
                55-80   & 6 \\
                80-105  & 4 \\
                105-130 & 3 \\
                \bottomrule
            \end{tabular}
        \end{center}
        Mode = $30 + \frac{3}{3+4} \times 25 = 40.71$
    \end{frame}


    \begin{frame}{Median}
        \begin{itemize}
            \item The median is the middle value of a dataset when the observations are arranged in ascending or descending order
            \item If the number of observations $n$ is odd, the median is the $(\frac{n+1}{2})^{\text{th}}$ observation
            \item If $n$ is even, the median is the average of the $(\frac{n}{2})^{\text{th}}$ and $\left(\frac{n}{2}+1\right)^{\text{th}}$ observations
            \item The median divides the dataset into two equal halves
            \item Therefore, it is the value below which 50\% of the data lies
            \item It is not affected by extreme values (outliers)
            \item Therefore, it is useful for skewed distributions or data with outliers
        \end{itemize}
    \end{frame}


    \begin{frame}{Median for Grouped Data}
        \[
            \textsf{Median} = L_m + \frac{\frac{n}{2} - F_c}{f_m} \times c,
        \]
        where:
        \begin{itemize}
            \item $L_m$ = lower limit of the median group, it is the group in which relative cumulative frequency is equal to 0.5 (50\%) or the first group in which relative cumulative frequency exceeds 0.5
            \item $n$ = sample size
            \item $F_c$ = cumulative frequency of the pre-median class
            \item $f_m$ = frequency of the median class
            \item $c$ is the class interval
        \end{itemize}
    \end{frame}


    \begin{frame}{Example: Median for Grouped Data}
        \begin{center}
            \begin{tabular}{lcc}
                \toprule
                \textbf{Class interval} & \textbf{Frequency} & \textbf{Cumulative Frequency}\\
                \midrule
                5-30    & 7  & 7\\
                30-55   & 10 & 17\\
                55-80   & 6  & 23\\
                80-105  & 4  & 27\\
                105-130 & 3  & 30\\
                \bottomrule
            \end{tabular}
        \end{center}
        Here, sample size is 30. Since 50\% of 30 is 15, the second group is the median class.\\[0.25em]

        Median = $L_m + \frac{\frac{n}{2} - F_c}{f_m} \times c = 30 + \frac{\frac{30}{2} - 7}{10} \times 25 = 50$.
    \end{frame}


    \begin{frame}{Trimmed Mean}
        \begin{itemize}
            \item The trimmed mean is a measure of central tendency obtained by removing a fixed proportion of the smallest and largest observations
            \item After trimming, the arithmetic mean is computed using the remaining data
            \item A $p\%$ trimmed mean removes the lowest $p\%$ and highest $p\%$ of the data
            \item It is less sensitive to extreme values than the arithmetic mean
            \item The trimmed mean provides a balance between the mean and the median
            \item It is useful when the data contain outliers or are moderately skewed
        \end{itemize}
    \end{frame}


    \begin{frame}{Quantile}
        \begin{itemize}
            \item Quantiles are values that divide an ordered dataset into equal parts
            \item Each part contains the same proportion of observations
            \item Common quantiles include:
            \begin{itemize}
                \item Quartiles: divide the data into four equal parts
                \item Deciles: divide the data into ten equal parts
                \item Percentiles: divide the data into one hundred equal parts
            \end{itemize}
            \item The median is the second quartile ($Q_2$) or the 50th percentile, it divides the data in two parts
            \item Quantiles are useful for describing the distribution and spread of data
        \end{itemize}
    \end{frame}


    \begin{frame}{Quartile}
        \begin{itemize}
            \item Quartiles are values that divide an ordered dataset into four equal parts
            \item Each part contains approximately 25\% of the observations
            \item The three quartiles are:
            \begin{itemize}
                \item First quartile ($Q_1$): 25th percentile
                \item Second quartile ($Q_2$): 50th percentile (the median)
                \item Third quartile ($Q_3$): 75th percentile
            \end{itemize}
            \item Quartiles are used to describe the spread and position of data
            \item Sometimes, the minimum value is referred to as the 0th quartile and the maximum value as the 4th quartile
        \end{itemize}
    \end{frame}


    \begin{frame}{Percentile}
        \begin{itemize}
            \item Percentiles divide an ordered dataset into 100 equal parts
            \item Each percentile represents 1\% of the observations
            \item The $p^{\text{th}}$ percentile is the value below which $p\%$ of the data lie
            \item The median is the $50^{\text{th}}$ percentile, the first quartile is the $25^{\text{th}}$ percentile, the third quartile is the $75^{\text{th}}$ percentile
            \item Percentiles are widely used in examinations, test scores, and rankings
        \end{itemize}
        Someone's IQ score being 90th percentile means that the score is above 90\% of the population.
    \end{frame}


    \begin{frame}{Calculating Percentile}
        \begin{itemize}
                \item First, arrange the data in ascending order
                \item In order to find the $i^{\text{th}}$ percentile, $p_i$, calculate: $\frac{i \cdot n}{100}$
                \item If $\frac{i \cdot n}{100}$ is an integer, then $p_i$ is the average of the $\left(\frac{i \cdot n}{100}\right)^{\text{th}}$ value and the value to its right
                \item If $\frac{i \cdot n}{100}$ is not an integer, then the integer to the right of $\frac{i \cdot n}{100}$ is $p_i$
        \end{itemize}
    \end{frame}


    \begin{frame}{Example: Calculating Percentile}
        Find the $90^{\text{th}}$ and $20^{\text{th}}$ percentiles from the test scores of 25 students: $43, 54, 56, 61, 62, 66, 68, 69, 69, 70, 71, 72, 77, 78, 79, 85, 87, 88, 89, 93, 95, 96, 98,$\\ $99, 99$.
        \vspace{1em}

        $\mathbf{90}^{\textbf{th}}$ \textbf{percentile}: $\frac{90 \times 25}{100} = 22.5$. Therefore, the $23^{\text{rd}}$ value is the $90^{\text{th}}$ percentile, which is $98$.
        \vspace{1em}

        $\mathbf{20}^{\textbf{th}}$ \textbf{percentile}: $\frac{20 \times 25}{100} = 5$. Therefore, the average of the $5^{\text{th}}$ and the $6^{\text{th}}$ values, is the desired percentile, which is $\frac{62+66}{2}=64$.
    \end{frame}


    \begin{frame}{Decile}
        \begin{itemize}
            \item Deciles divide an ordered dataset into 10 equal parts
            \item Each decile represents 10\% of the observations
            \item The $k^{\text{th}}$ decile ($D_k$) is the value below which $k \times 10\%$ of the data lie
            \item The fifth decile ($D_5$) coincides with the median
            \item Deciles are useful for studying the distribution of data in broader groups
            \item Can be calculated the same way as percentiles are calculated
        \end{itemize}
    \end{frame}

    
    \section{Dispersion}


    \begin{frame}{Dispersion}
        \begin{itemize}
            \item Dispersion describes the extent to which data values are spread out
            \item It indicates the variability or consistency present in a dataset
            \item A low dispersion indicates that data values are close to each other, while a high dispersion indicates greater variability
            \item Measures of dispersion complement measures of central tendency
            \item Common measures of dispersion include:
            \begin{itemize}
                \item Range
                \item Interquartile range
                \item Mean deviation, Mean absolute deviation
                \item Variance and standard deviation
            \end{itemize}
            \item Dispersion is essential for comparing datasets with similar central tendencies.
        \end{itemize}
    \end{frame}


    \begin{frame}{Comparing Different Levels of Dispersion}
        \centering
        \includegraphics[width=0.8\textwidth]{plots/dispersion-comparison.pdf}
    \end{frame}


    \begin{frame}{Range}
        \begin{itemize}
            \item The range is the simplest measure of dispersion
            \item It gives a quick idea of the overall spread of the data
            \item It is defined as the difference between the largest and smallest observations in a dataset
            \item If the minimum value is $\min(x)$ and the maximum value is $\max(x)$, then
            \[
                \text{Range} = \max(x) - \min(x)
            \]
            \item It is highly sensitive to extreme values (outliers)
            \item The range does not use all observations and provides only a rough measure of variability
        \end{itemize}
    \end{frame}


    \begin{frame}{Inter-quartile Range}
        \begin{itemize}
            \item The interquartile range (IQR) is a measure of dispersion based on quartiles
            \item It is defined as the difference between the third and first quartiles
            \[
                \textsf{IQR} = Q_3 - Q_1
            \]
            \item The IQR measures the spread of the middle 50\% of the data
            \item Threfore it is not affected by extreme values or outliers
            \item The IQR is particularly useful for skewed distributions
            \item It is commonly used to identify outliers
        \end{itemize}
    \end{frame}


    \begin{frame}{Mean Deviation}
        \begin{itemize}
            \item The mean deviation is defined as the arithmetic mean of deviations from the mean
            \item For observations $x_1, x_2, \dots, x_n$ with mean $\bar{x}$,
            \[
                \frac{1}{n} \sum_{i=1}^{n} (x_i - \bar{x})
            \]
            \item The positive and negative deviations cancel each other out
            \item As a result, the value of this mean deviation is always zero
            \item Because it is always zero, it is not useful as a measure of dispersion
            \item This limitation motivates the use of absolute deviations or squared deviations
        \end{itemize}
    \end{frame}


    \begin{frame}{Mean Absolute Deviation}
        \begin{itemize}
            \item Mean absolute deviation is defined as the arithmetic mean of the absolute deviations of observations from a central value
            \item For observations $x_1, x_2, \dots, x_n$ with mean $\bar{x}$,
            \[
                \text{Mean Deviation} = \frac{1}{n} \sum_{i=1}^{n} |x_i - \bar{x}|.
            \]
            \item Mean deviation uses all observations in the dataset
            \item It is less affected by extreme values than variance and standard deviation
        \end{itemize}
    \end{frame}


    \begin{frame}{Variance}
        \begin{itemize}
            \item It is based on squared deviations from the mean and measures how far observations spread out from the mean, on average
            \item For a population, the variance is
            \[
                \sigma^2 = \frac{1}{N} \sum_{i=1}^{N} (x_i - \mu)^2
            \]
            \item For a sample, the variance is
            \[
                s^2 = \frac{1}{n-1} \sum_{i=1}^{n} (x_i - \bar{x})^2
            \]
            \item Squaring the deviations removes cancellation of positive and negative values
            \item Variance uses all observations and is sensitive to extreme values
            \item The units of variance are the square of the original data units
        \end{itemize}
    \end{frame}


    \begin{frame}{Standard Deviation}
        \begin{itemize}
            \item Standard deviation is a widely used measure of dispersion
            \item It measures the average spread of observations around the mean
            \item It is defined as the square root of the variance.
            \item For a population, the standard deviation is
            \[
                \sigma = \sqrt{\frac{1}{N} \sum_{i=1}^{N} (x_i - \mu)^2}
            \]
            \item For a sample, the standard deviation is
            \[
                s = \sqrt{\frac{1}{n-1} \sum_{i=1}^{n} (x_i - \bar{x})^2}
            \]
            \item Standard deviation uses all observations and is sensitive to extreme values
            \item It is expressed in the same units as the original data
        \end{itemize}
    \end{frame}


    \begin{frame}{Coefficient of Variation}
        \begin{itemize}
            \item The coefficient of variation is a relative measure of dispersion (the ones before this were absolute measures)
            \item It expresses variability relative to the mean of the dataset
            \item The coefficient of variation is defined as
            \[
                \text{CV} = \frac{\text{standard deviation}}{\text{mean}}.
            \]
            \item It is often expressed as a percentage:
            \[
                \text{CV} = \frac{s}{\bar{x}} \times 100\%
            \]
            \item The coefficient of variation is unit-free
            \item The coefficient of variation is meaningful only when the mean is non-zero
        \end{itemize}
    \end{frame}


    \begin{frame}{Coefficient of Variation (cont.)}
        \begin{itemize}
            \item The coefficient of variation is useful for comparing variability between datasets with different units or different means
            \item For example, suppose two cricket batsmen both have average score of $50$, and average standard deviation of $10$ and $20$ respectively.
            \item The first batsman has a CV of $10/50=0.2$ and the second batsman has CV of $10/60=0.167$
            \item This means that while both have SD of $10$, the second batsman is more preferable
        \end{itemize}
    \end{frame}


    \begin{frame}{Example}
        Calculate measures of dispersion from the weight of ten newborn babies (in pounds): $7.5, 4.5, 10.1, 9.6, 5.5, 6.6, 7.8, 5.9, 6.0, 5.5$.
        \vspace{0.5em}

        \textbf{Range} = $10.1 - 4.5 = 5.6$ pounds
        \vspace{0.5em}

        \textbf{Mean,} $\bar{x} = \frac{7.5 + 4.5 +...+ 5.5}{10} = 6.9$ pounds
        \vspace{0.5em}

        \textbf{Variance,} $s^2 = \frac{(7.5-6.9)^2 + (4.5-6.9)^2 + ... + (5.5-6.9)^2}{10-1}=\frac{30.28}{9}=3.36 \, \text{pound}^2$
        \vspace{0.5em}

        \textbf{Standard deviation (SD),} $s = \sqrt{3.36} = 1.83$ pound
        \vspace{0.5em}

        \textbf{Coefficient of Variation, CV} $= \frac{s}{\bar{x}} = \frac{1.83}{6.9} = 0.2652$
    \end{frame}


    \section{Shape of Distribution}

    \begin{frame}{Shape of Distribution}
        \begin{itemize}
            \item \textbf{Shape of distribution}: describes the overall form of the data, including symmetry, number of peaks, and tail behaviour
            \item \textbf{Skewness}: indicates the direction and degree of asymmetry in a distribution
            \item \textbf{Kurtosis}: reflects the peakedness of the distribution and the heaviness of its tails
            \item These characteristics help summarize how data are distributed beyond measures of central tendency
            \item They guide the choice of appropriate statistical methods and models
        \end{itemize}
    \end{frame}


    \begin{frame}{Skewness}
        \begin{itemize}
            \item \textbf{Skewness} measures the asymmetry of a distribution around its center
            \item A distribution is \textbf{symmetric} if the left and right sides are mirror images
            \item \textbf{Positive (right) skewness}: longer tail on the right side
            \item \textbf{Negative (left) skewness}: longer tail on the left side
            \item Skewness affects the relative positions of the mean, median, and mode
        \end{itemize}
    \end{frame}


    \begin{frame}{Symmetric Distribution}
        \begin{center}
            \includegraphics[width=0.6\textwidth]{plots/symmetric.pdf}
        \end{center}
        Above is a symmetric (bell shaped) distribution. \vspace{0.25em}

        In such cases: mean = median = mode.
    \end{frame}


    \begin{frame}{Left Skewed Distribution}
        \begin{center}
            \includegraphics[width=0.6\textwidth]{plots/left-skewed.pdf}
        \end{center}
        Here: mode > median > mean.
    \end{frame}


    \begin{frame}{Right Skewed Distribution}
        \begin{center}
            \includegraphics[width=0.6\textwidth]{plots/right-skewed.pdf}
        \end{center}
        Here: mean > median > mode.
    \end{frame}


    \begin{frame}{Caluclating Skewness}
        \begin{itemize}
            \item Pearson's Coefficient of Skewness $= \frac{3(\text{mean}-\text{median})}{\text{Standard deviation}}$
            \item Bowley's coefficient of skewness $= \frac{(Q_3-Q_2)-(Q_2-Q_1)}{(Q_3-Q_1)}$
            \item If the coefficient is positive, then the distribution is right skewed
            \item Left skewed if the coefficient is negative
            \item Symmetric if the coefficient is zero
        \end{itemize}
    \end{frame}


    \begin{frame}{Kurtosis}
        \begin{itemize}
            \item \textbf{Kurtosis} describes the peakedness and tail heaviness of a distribution
            \item It indicates how concentrated the data are around the mean
            \item \textbf{Leptokurtic}: sharper peak with heavier tails
            \item \textbf{Mesokurtic}: peak not too sharp and tails neither heavy nor light
            \item \textbf{Platykurtic}: flatter peak with lighter tails
        \end{itemize}
    \end{frame}


    \begin{frame}{Kurtosis Comparison}
        \begin{center}
            \includegraphics[width=0.8\textwidth]{plots/kurtosis-comparison.pdf}
        \end{center}
    \end{frame}

    
    \begin{frame}{Calculating Kurtosis}
        \[
            \text{Kurtosis} = \frac{\frac{\sum (x_i - \bar{x})^4}{n}}{\left(\frac{\sum (x_i - \bar{x})^2}{n}\right)^2}-3
        \]

        \begin{itemize}
            \item If kurtosis = 0, then the distribution is mesokurtic
            \item If it is positive, then leptokurtic
            \item If it is negative, then platykurtic
        \end{itemize}
    \end{frame}


    \section{Outlier}

    \begin{frame}{Outlier}
        \begin{itemize}
            \item Outliers are observations that are different from the rest of the data
            \item They may arise due to measurement errors, data entry errors, or genuine extreme values
            \item Outliers can strongly affect measures such as the mean, variance, and standard deviation
            \item Measures like the median and interquartile range are more resistant to outliers
            \item A common rule for identifying outliers is based on the interquartile range:
            \[
                \text{Lower bound} = Q_1 - 1.5 \times \text{IQR}, \quad
                \text{Upper bound} = Q_3 + 1.5 \times \text{IQR}
            \]
            \item Values outside this range are considered outliers
            \item Outliers should be investigated carefully before being removed
        \end{itemize}
    \end{frame}


    \section{Boxplot}

    % \begin{frame}{Boxplot}
    %     \begin{center}
    %         \includegraphics[width=\textwidth]{plots/boxplot.pdf}
    %     \end{center}
    % \end{frame}

    \begin{frame}{Boxplot}
        \begin{center}
            \includegraphics[width=\textwidth]{plots/boxplot.pdf}
        \end{center}

        \vfill

        \begin{itemize}
            \item A boxplot is a graphical method for summarizing the distribution of a dataset
            \item It is based on the five-number summary: a lower fence, $Q_1$, median ($Q_2$), $Q_3$, and an upper fence
            \item The box represents the interquartile range ($Q_3 - Q_1$)
            \item The line inside the box indicates the median
        \end{itemize}
    \end{frame}


    \begin{frame}{Boxplot (cont.)}
        \begin{center}
            \includegraphics[width=\textwidth]{plots/boxplot-annotated.pdf}
        \end{center}

        \vfill

        \begin{itemize}
            \item \textbf{Lower fence} $=Q_1 - 1.5 \times \text{IQR}$, \textbf{upper fence} $=Q_3 + 1.5 \times \text{IQR}$
            \item Whiskers extend to the smallest and largest non-outlier observations (lower fence and upper fence)
            \item Observations beyond the whiskers are plotted individually as outliers
            \item Thus boxplots can be used to detect outliers graphically
        \end{itemize}
        % \vspace{1.28em}
    \end{frame}


    \begin{frame}{Comparing Groups with Boxplot}
        \begin{center}
            \includegraphics[width=\textwidth]{plots/boxplot-pair.pdf}
        \end{center}
        Section 2 has lower average (median) score, but its maximum score is higher than that of section 1. Further, section 2 has higher variability.
    \end{frame}


    \begin{frame}{Identifying Skewness with Boxplots}
        \begin{itemize}
            \item Boxplots can also help identifying the shape (skewness) of the distribution of numeric variables
            \item The position of the quartiles relative to the median as well as the length of the whiskers can help determine the shape
        \end{itemize}
    \end{frame}


    \begin{frame}{Identifying Skewness with Boxplots: Symmetric Distribution}
        \begin{center}
            \includegraphics[width=\textwidth]{plots/boxplot-symmetric.pdf}
        \end{center}

        \begin{itemize}
            \item The median is approximately at the center of the box
            \item The whiskers are of approximately equal length
        \end{itemize}
    \end{frame}


    \begin{frame}{Identifying Skewness with Boxplots: Left Skewed}
        \begin{center}
            \includegraphics[width=\textwidth]{plots/boxplot-left-skewed.pdf}
        \end{center}

        \begin{itemize}
            \item The median is at the right portion of the box
            \item The left whisker/tail is longer than the one on the right
        \end{itemize}
    \end{frame}


    \begin{frame}{Identifying Skewness with Boxplots: Right Skewed}
        \begin{center}
            \includegraphics[width=\textwidth]{plots/boxplot-right-skewed.pdf}
        \end{center}

        \begin{itemize}
            \item The median is at the left portion of the box
            \item The right whisker/tail is longer than the one on the left
        \end{itemize}
    \end{frame}


    \section*{Questions?}


\end{document}